{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfc2d232-20d9-4691-831f-16198bf89726",
   "metadata": {},
   "source": [
    "### FFMPEG\n",
    "#### https://pypi.org/project/ffmpeg-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a49617-8f01-4f5c-b7fb-16b877b89c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для установки библиотеки (ячейку достаточно выполнить один раз)\n",
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ac0a2-1f86-4563-a860-461c007b1175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотеки\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2851d-aa55-40a2-9ac6-ad13290b2430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка деления\n",
    "# Путь до видео\n",
    "video_path = \"/Users/vladislav/Documents/JupyterNotebook/ObjectDetection/Maintenance Hand Segmentation/Python Segmentation/pump_dataset/pump_videos/test_pump_video.mp4\"\n",
    "stream = ffmpeg.input(video_path)\n",
    "\n",
    "stream = ffmpeg.trim(stream, start_frame=236, end_frame=241)\n",
    "stream = ffmpeg.output(stream, \"test2.mp4\") # Отделенные кадры видео сохранятся в ту же папку, где расположен этот notebook\n",
    "ffmpeg.run(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad65f178-5b6e-4d20-a341-4498aee146d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Секунды, на которых происходит смена действия для видео test_pump_video.mp4\n",
    "cuts_number = [6,16,27,40,52,70,80,100,120,130,164,172,178,184,225,300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b18576-9b56-4e96-b794-a0b3e181ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Алгоритм деления:\n",
    "# start_frame - первое значение в массиве, end_frame - следующее значение в массиве\n",
    "# Повторяем предыдущее действие до ех пор пока не дойдем до последнего элемента в массиве cuts_number\n",
    "for i in range(len(cuts_number)):\n",
    "    if i+1 != len(cuts_number):\n",
    "        stream = ffmpeg.input(\"/Users/vladislav/Documents/JupyterNotebook/ObjectDetection/Maintenance Hand Segmentation/Python Segmentation/pump_dataset/pump_videos/test_pump_video.mp4\")\n",
    "        stream = ffmpeg.trim(stream, start_frame=cuts_number[i], end_frame=cuts_number[i+1])\n",
    "        filename = \"detection_\" + str(cuts_number[i]) + \"_\" + str(cuts_number[i+1]) + \".mp4\"\n",
    "        stream = ffmpeg.output(stream, filename)\n",
    "        ffmpeg.run(stream)\n",
    "        print(cuts_number[i], \" \", cuts_number[i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c0405-2a96-4c93-a3b0-1453f310782b",
   "metadata": {},
   "source": [
    "### SceneDetectPy\n",
    "#### Еще одна библиотека для деление видео на сцены https://pypi.org/project/scenedetect/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "906c4309-6551-45dc-b588-f8b3fcd429dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scenedetect in /Users/vladislav/miniforge3/envs/tensorflow/lib/python3.8/site-packages (0.6.1)\n",
      "Requirement already satisfied: appdirs in /Users/vladislav/miniforge3/envs/tensorflow/lib/python3.8/site-packages (from scenedetect) (1.4.4)\n",
      "Requirement already satisfied: Click in /Users/vladislav/miniforge3/envs/tensorflow/lib/python3.8/site-packages (from scenedetect) (8.1.3)\n",
      "Requirement already satisfied: numpy in /Users/vladislav/miniforge3/envs/tensorflow/lib/python3.8/site-packages (from scenedetect) (1.22.4)\n",
      "Requirement already satisfied: tqdm in /Users/vladislav/miniforge3/envs/tensorflow/lib/python3.8/site-packages (from scenedetect) (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "# Установка библиотеки\n",
    "!pip install scenedetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ce1023-4a8c-469d-a55b-0981effa53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/Users/vladislav/Documents/JupyterNotebook/ObjectDetection/Maintenance Hand Segmentation/Python Segmentation/pump_dataset/pump_videos/test_pump_video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e43fc9-42ec-43bb-8509-6c5bed41bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get started, there is a high level function in the library that performs content-aware scene detection on a video (try it from a Python prompt):\n",
    "from scenedetect import detect, ContentDetector\n",
    "scene_list = detect(video_path, ContentDetector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035a1f75-efa6-4d57-8eb1-842d04128dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(00:00:00.000 [frame=0, fps=24.999], 00:02:33.808 [frame=3845, fps=24.999]),\n",
       " (00:02:33.808 [frame=3845, fps=24.999],\n",
       "  00:03:44.172 [frame=5604, fps=24.999]),\n",
       " (00:03:44.172 [frame=5604, fps=24.999],\n",
       "  00:03:46.292 [frame=5657, fps=24.999]),\n",
       " (00:03:46.292 [frame=5657, fps=24.999],\n",
       "  00:04:06.813 [frame=6170, fps=24.999]),\n",
       " (00:04:06.813 [frame=6170, fps=24.999],\n",
       "  00:04:38.934 [frame=6973, fps=24.999]),\n",
       " (00:04:38.934 [frame=6973, fps=24.999],\n",
       "  00:04:39.855 [frame=6996, fps=24.999]),\n",
       " (00:04:39.855 [frame=6996, fps=24.999],\n",
       "  00:04:42.455 [frame=7061, fps=24.999]),\n",
       " (00:04:42.455 [frame=7061, fps=24.999],\n",
       "  00:04:59.256 [frame=7481, fps=24.999]),\n",
       " (00:04:59.256 [frame=7481, fps=24.999],\n",
       "  00:05:07.376 [frame=7684, fps=24.999])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "870e5352-e448-41fc-8e27-8e0f0a51cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Scene  1: Start 00:00:00.000 / Frame 0, End 00:02:33.808 / Frame 3845\n",
      "    Scene  2: Start 00:02:33.808 / Frame 3845, End 00:03:44.172 / Frame 5604\n",
      "    Scene  3: Start 00:03:44.172 / Frame 5604, End 00:03:46.292 / Frame 5657\n",
      "    Scene  4: Start 00:03:46.292 / Frame 5657, End 00:04:06.813 / Frame 6170\n",
      "    Scene  5: Start 00:04:06.813 / Frame 6170, End 00:04:38.934 / Frame 6973\n",
      "    Scene  6: Start 00:04:38.934 / Frame 6973, End 00:04:39.855 / Frame 6996\n",
      "    Scene  7: Start 00:04:39.855 / Frame 6996, End 00:04:42.455 / Frame 7061\n",
      "    Scene  8: Start 00:04:42.455 / Frame 7061, End 00:04:59.256 / Frame 7481\n",
      "    Scene  9: Start 00:04:59.256 / Frame 7481, End 00:05:07.376 / Frame 7684\n"
     ]
    }
   ],
   "source": [
    "#Try calling print(scene_list), or iterating over each scene:\n",
    "from scenedetect import detect, ContentDetector\n",
    "scene_list = detect(video_path, ContentDetector())\n",
    "for i, scene in enumerate(scene_list):\n",
    "    print('    Scene %2d: Start %s / Frame %d, End %s / Frame %d' % (\n",
    "        i+1,\n",
    "        scene[0].get_timecode(), scene[0].get_frames(),\n",
    "        scene[1].get_timecode(), scene[1].get_frames(),))\n",
    "\n",
    "#We can also split the video into each scene if ffmpeg is installed (mkvmerge is also supported):\n",
    "from scenedetect import detect, ContentDetector, split_video_ffmpeg\n",
    "scene_list = detect(video_path, ContentDetector())\n",
    "split_video_ffmpeg(video_path, scene_list)\n",
    "\n",
    "#For more advanced usage, the API is highly configurable, and can easily integrate with any pipeline. This includes using different detection algorithms, splitting the input video, and much more. The following example shows how to implement a function similar to the above, but using the scenedetect API:\n",
    "from scenedetect import open_video, SceneManager, split_video_ffmpeg\n",
    "from scenedetect.detectors import ContentDetector\n",
    "from scenedetect.video_splitter import split_video_ffmpeg\n",
    "\n",
    "def split_video_into_scenes(video_path, threshold=27.0):\n",
    "    # Open our video, create a scene manager, and add a detector.\n",
    "    video = open_video(video_path)\n",
    "    scene_manager = SceneManager()\n",
    "    scene_manager.add_detector(\n",
    "        ContentDetector(threshold=threshold))\n",
    "    scene_manager.detect_scenes(video, show_progress=True)\n",
    "    scene_list = scene_manager.get_scene_list()\n",
    "    split_video_ffmpeg(video_path, scene_list, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deffb56e-972b-439c-8f14-817362070a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
